---
output: html_document
editor_options: 
  chunk_output_type: console
---
# (APPENDIX) Appendix {-} 

# Useful code examples

## Use of acronyms

To begin, let's see how the list of acronyms is working. The acronyms are defined in the file `abbreviations.tex`, see an explanation of how to do that in the file itself. Regarding the use of these acronyms inside of the text: In the source code, one writes something as follows, using standard \LaTeX\ commands:

```
First use: \Ac{cran}. Second use: \ac{cran}. First use of another abbreviation: 
\ac{ide}, then the plural use: \acp{ide}. And here you see that \acs{H2O} 
is actually \ac{H2O}.
```

This displays as follows:

> First use: \Ac{cran}. Second use: \ac{cran}. 
> First use of another abbreviation: \ac{ide}, then the plural use: \acp{ide}. 
> And here you see that \acs{H2O} is actually \ac{H2O}.

## Load packages and read data into R {#read-data}

At the beginning of your book, you should put all necessary packages in one chunk, then loading the data in the next chunk so that these steps are properly organized:


```{r}
#| echo = TRUE,
#| message = FALSE
library(tidyverse) # This includes readr!
library(xtable) # For displaying LaTeX tables
library(modelsummary) # For displaying regression models in tables
library(stargazer) # For displaying regression models in tables
library(jtools) # For displaying regression models in tables
library(kableExtra) # For displaying or changing tables
library(gt) # For displaying tables
library(gtsummary) # For model reporting inline and in tables
library(broom) # For working with statistical models
library(car) # For type-III anova tests
library(report) # For automated text-based model reporting
library(effects) # For working with statistical models / visualize effects
library(ggeffects) # For working with statistical models / visualize effects
library(patchwork) # For putting different visualizations in one figure
```

One of the most common ways to get your data into R is to place them into your project directory as a CSV-file and read them into the current session, that is, the session of the produced book, using [readr](https://cran.r-project.org/web/packages/readr/) (https://cran.r-project.org/web/packages/readr/). 


```{r}
#| echo = TRUE,
#| message = TRUE
df1 <- read_csv("02-data/mpg_data_as_csv.csv", lazy = FALSE)
```

You can then use the function arguments to change necessary things like the delimiter (also switching to `readr::read_delim()` instead of `readr::read_csv()` to do this), or see the specifics of the column types using `read::spec()` and change them accordingly if needed.


```{r}
#| echo = TRUE,
#| message = TRUE
spec(df1)

df1 <- read_delim("02-data/mpg_data_as_csv.csv",
                  delim = ",",
                  col_types = cols(
                      manufacturer = col_character(),
                      model = col_character(),
                      displ = col_double(),
                      year = col_double(),
                      cyl = col_double(),
                      trans = col_character(),
                      drv = col_character(),
                      cty = col_double(),
                      hwy = col_double(),
                      fl = col_character(),
                      class = col_character()
                      ), lazy = FALSE
                  )

```


## Displaying different types of tables from modelsummary

The data set is part of the [ggplot2](https://cran.r-project.org/web/packages/ggplot2/) package (https://cran.r-project.org/web/packages/ggplot2/) and is originally named `mpg`. To display a summary of the data set in your work, you may use, for example, the modelsummary package with its function `modelsummary::datasummary_skim()`, from which the output can be seen in table \@ref(tab:skim-df1). Don't forget to name the chunk and specify the table caption using the argument `title` in the function call! Without these two adjustments, you cannot cross-reference this table and it does not appear in the list of tables in the frontmatter. Another source of error is the naming of the chunks: Never use underscores in these, only letters and minus signs! And always place a blank line in front and after a code chunk.

```{r}
#| label = "skim-df1",
#| echo = TRUE
# You can reference this table now with "\@ref(tab:skim-df1)".
# The part with kable_styling is coming from the kableExtra package and 
# changes the position of the table and its appearance
datasummary_skim(df1, output = 'kableExtra', booktabs = TRUE,
        title = "Overview of the numerical variables in data set df1") %>%
    kable_styling(latex_options = c("striped", "HOLD_position"))
```


Another useful table can be produced by using the function `datasummary_correlation()` from the same package. Its output can be seen in table \@ref(tab:corr-df1), which in addition is changed to show how to use footnotes using `kableExtra`. The content of the footnote is also true for table \@ref(tab:skim-df1), so be careful and adjust variable types before doing something with them such as in table \@ref(tab:skim-df1-cat).

```{r}
#| label = "corr-df1",
#| echo = TRUE
df1_footnote <- df1
names(df1_footnote)[names(df1_footnote) == "year"] <- 
    paste0(names(df1_footnote)[names(df1_footnote) == "year"], 
           footnote_marker_symbol(1, "latex"))

datasummary_correlation(df1_footnote, output = 'kableExtra',
        booktabs = TRUE, escape = FALSE, # 'escape = FALSE' here is important!
        title = "Correlations of numerical variables in data set df1") %>% 
    kable_styling(latex_options = c("striped", "HOLD_position")) %>% 
    footnote(symbol = paste0("Using the categorical variable",
                             " 'year' here in a correlation is :-("),
             threeparttable = TRUE) # This last options enables the line break!
```


Adjusting all categorical variables to the correct type:

```{r}
#| echo = TRUE
df1 <- df1 %>% 
    mutate(manufacturer = factor(manufacturer),
           model = factor(model),
           year = factor(year),
           cyl = ordered(cyl, 
                         levels = c(4,5,6,8),
                         labels = c("4 Cylinders",
                                    "5 Cylinders",
                                    "6 Cylinders",
                                    "8 Cylinders")),
           trans = factor(trans),
           drv = factor(drv, 
                        levels = c("f", "r", "4"),
                        labels = c("Front wheel drive",
                                   "Rear wheel drive",
                                   "4 wheel drive")),
           fl = factor(fl),
           class = factor(class)) 
```


Now using another kind of table from the `modelsummary` package:

```{r}
#| label = "skim-df1-cat",
#| echo = TRUE
datasummary_crosstab(drv ~ year, 
                     data = df1, booktabs = TRUE,
        title = "Cross tabulations for year and type of drive") %>% 
    kable_styling(latex_options = c("striped", "HOLD_position"))

```

See the `datasummary` vignettes for more possibilities: 

> https://vincentarelbundock.github.io/modelsummary/articles/datasummary.html


## Reporting statistical models

### $t$-test

In the following paragraphs, I want to give some examples on how to report a statistical model. Let's start with a simple one, an independent two sample $t$-test:

\begin{equation} 
  t = \frac{m_A - m_B}{\sqrt{ \frac{s^2}{n_A} + \frac{s^2}{n_B} }}
  (\#eq:t-test)
\end{equation} 

where $s^2$ is an estimator of the common variance of the two samples. It can be calculated as 

\begin{equation} 
  s^2 = \frac{\sum{(x-m_A)^2}+\sum{(x-m_B)^2}}{n_A+n_B-2}
  (\#eq:t-test-s)
\end{equation} 

Once the $t$-test statistic value is calculated, one uses the critical value of Studentâ€™s $t$-distribution corresponding to the significance level alpha of your choice (5%). The degrees of freedom ($df$) used in this test are $df = n_A + n_B - 2$. We can simulate some data according to equation \@ref(eq:t-test) and apply the function `t.test()` from the `stats` package:

```{r}
#| echo = TRUE
N <- 100
delta <- 5
same_sd <- 5
df_ttest <- tibble(class = gl(n = 2, k = N/2, labels = c("Class A", "Class B")),
                   exam_score = c(rnorm(N/2, mean = 50, sd = same_sd),
                                  rnorm(N/2, mean = 50 + delta, sd = same_sd)))
test1 <- t.test(exam_score ~ class, data = df_ttest, var.equal = TRUE)
test1_glance <- glance(test1)
test1
```

This console output is not very pleasant and should not be reported as this. Better to use the package `broom` and its function `broom::glance()` to extract everything you need using inline code chunks, which gives you a significant difference of $\approx~`r round(test1_glance$estimate, digits = 2)`$ between class A ($M = `r round(test1_glance$estimate1, digits = 2)`$, $SD = `r round(sd(df_ttest$exam_score[df_ttest$class == "Class A"]), digits = 2)`$) and class B ($M = `r round(test1_glance$estimate2, digits = 2)`$, $SD = `r round(sd(df_ttest$exam_score[df_ttest$class == "Class B"]), digits = 2)`$) in this case, $t(`r test1_glance$parameter`)~=~`r round(test1_glance$statistic, digits = 3)`,~p~`r ifelse(round(test1_glance$p.value, digits = 3) == 0, "<~.001", paste0("=~", round(test1_glance$p.value, digits = 3)))`$. You should read the source code of this paragraph carefully to see how everything in the inline chunks fits together to produce such an output. 


### $\chi^2$-test

The same procedure can be used to report a $\chi^2$-test using the function `chisq.test()` from the `stats` package. This time, let's use the `mpg` data set imported above in section \@ref(read-data):

```{r}
#| echo = TRUE,
#| warning = FALSE
# Build a contingency table for year and cylinders
tbl_df <- table(df1$year, df1$cyl)
chi_test <- chisq.test(tbl_df)
chi_result <- glance(chi_test)
tbl_df
chi_test
chi_result
```

In this toy example, we can report that the cell means appear to be significantly different from each other, in other words, that they are not independent, $\chi^2(`r chi_result$parameter`)~=~`r round(chi_result$statistic, digits = 3)`,~p~`r ifelse(round(chi_result$p.value, digits = 3) == 0, "<~.001", paste0("=~", round(chi_result$p.value, digits = 3)))`$.

Because it is very tedious to use the `ifelse()` command inside an inline code chunk to print the $p$-value correctly, one can define a function for printing the $p$-value that simplifies the source code a little bit like in the following code chunk. 


```{r}
#| echo = TRUE
print_p_value <- function(p.num, DIGITS = 3) {
    if (abs(p.num) < 0.001) {
        number <- '<~.001'
    } else if (abs(p.num) > 0.9) {
        number <- '>~.9'
    } else {
        number <- paste0('=~',
                         stringr::str_replace(round(p.num, dig = DIGITS),
                                              '0\\.', '.'))
    }
    return(as.character(number))
}
```

This gives you the possibility to write the test as follows, $\chi^2(`r chi_result$parameter`)~=~`r round(chi_result$statistic, digits = 3)`,~p~`r print_p_value(chi_result$p.value)`$. Please look at the source code where the $\chi^2$-test is reported for the second time to see the difference to the inline code chunk from before.


### Linear regression models {#reg-models}

In this section, we will again use the data set loaded in section \@ref(read-data), where we formulate different linear regression models using the function `lm()` from the `stats` package to predict the outcome `hwy` (highway miles per gallon). The first one will be a more complicated model including a continuous predictor, `displ` (displacement), two categorical predictors, `year` and `cyl` (number of cylinders), and the interaction between the two categorical independent variables. The second one will be a model with all three predictors but without the interaction, and the third one will also omit the continuous predictor variable. Because there are only some cars with five cylinders, these observations are excluded beforehand to simplify the models. After fitting the three models that are all nested (the second is a simpler versions of the first, the third a simpler version of the second model), all three models are compared using the `anova()` function from the `stat` package, see table \@ref(tab:lm-anova), which is produced using the `broom` package and some `tidyverse` and `kableExtra` magic (again).


```{r}
#| label = "lm-anova",
#| echo = TRUE,
#| warning = FALSE
df1_small <- df1 %>% filter(cyl != "5 Cylinders") %>% 
    mutate(cyl = droplevels(cyl))

m1 <- lm(hwy ~ year + cyl + displ + year:cyl, 
         data = df1_small, 
         contrasts = list(year = "contr.treatment",
                          cyl = "contr.treatment"))
m2 <- update(m1, . ~ . - year:cyl)
m3 <- update(m2, . ~ . - displ)

tidy(anova(m1, m2, m3)) %>% 
    mutate(across(where(is.numeric), ~ as.character(round(.x, digits = 3)))) %>% 
    mutate(across(where(is.character), ~ if_else(is.na(.x), "", .x))) %>% 
    rename("Residual $df$" = `df.residual`,
           "RSS" = rss,
           "$df$" = df,
           "Sum of Squares" = sumsq,
           "Statistic" = statistic,
           "$p$-value" = p.value) %>%
    mutate(Model = c(formula(m1)[[3]], formula(m2)[[3]], formula(m3)[[3]])) %>% 
    select(Model, everything(), -term) %>% 
    kbl(caption = "Analysis of variance table for three linear models",
        booktabs = TRUE, escape = FALSE, align = "lcccrrr",
        centering = TRUE) %>% 
    kable_styling(latex_options = c("striped", "HOLD_position",
                                    "scale_down")) %>% 
    add_footnote(label = paste0("cyl = cylinder; ",
                                "displ = displacement; ",
                                "$df$ = degrees of freedom; ", 
                                "RSS = Residual Sum of Squares"),
                 notation = "none", escape = FALSE) 
```

If you want to know more about the underlying logic behind the statistical part, for example the meaning of analysis of variance in this situation, or what the change of the contrasts here is supposed to do, or what the heck contrasts are to begin with, I can only recommend reading! A good starting point would be the chapter about linear models from the manual *An Introduction into R* [@introR2022], the book *An R Companion to Applied Regression* by @fox2019, or the book *Regression Modeling Strategies* by @harrell2019. There are a lot of books about linear models out there and many of them are dealing with them using R, so it's up to you. If you want to know what the above code does, read it carefully and omit steps to see what element does what!

From the output of table \@ref(tab:lm-anova) we can see that in this toy data set case, the smallest model seems to be significantly better fitting the data than the intermediate model with one more predictor, and that there is no significant difference between the second and the most complicated model including the interaction. That means, model three would be better than the others. 

But, let's use different packages to produce a side by side table for all three models. The first example, see table \@ref(tab:m123-modelsummary), is produced using the `modelsummary` package:

```{r}
#| label = "m123-modelsummary",
#| echo = TRUE,
#| warning = FALSE
modelsummary(
    list("Model 1" = m1, "Model 2" = m2, "Model 3" = m3),
    output = "kableExtra", fmt = 2, booktabs = TRUE,
    escape = FALSE, statistic = NULL, stars = TRUE, 
    estimate = "{estimate} ({std.error}){stars}",
    coef_map = c(
        "(Intercept)" = "Constant",
        "year2008" = "Year = 2008",
        "cyl6 Cylinders" = "6 Cylinders",
        "cyl8 Cylinders" = "8 Cylinders",
        "displ" = "Displacement",
        "year2008:cyl6 Cylinders" = "2008 $\\times$ 6 Cylinders",
        "year2008:cyl8 Cylinders" = "2008 $\\times$ 8 Cylinders"
    ),
    gof_map = tribble(
        ~raw, ~clean, ~fmt,
        "nobs", "\\# Observations", 0,
        "adj.r.squared", "$adj.~R^2$", 2,
        "aic", "$AIC$", 2,
        "rmse", "$RMSE$", 2,
        "F", "$F$", 2
    ), 
    notes = paste0("{\\\\small \\\\textsl{Notes:}~", 
                   "$+~p~\\\\leq~.1$; ", 
                   "$*~p~\\\\leq~.05$; ",
                   "$**~p~\\\\leq~.01$; ",
                   "$***~p~\\\\leq~.001$}"),
    title = "Comparison of three linear models using modelsummary") %>%
    kable_styling(latex_options = c("striped", "HOLD_position")) 
```


Another variant would be to use the `stargazer` package, but here one has to apply several small extra steps to make this work in the bookdown environment we are working in. Firstly, you need to set the code chunk option `results = "asis"`, then you must set the label option in the stargazer function to the exact label you want to cross-reference to, including the "tab:" part, e.g., `label = "tab:m123-stargazer"`, and lastly you must specify the argument `header = FALSE` in the `stargazer` function call to suppress the message "Table built by...". Everything else is a question of using the correct options to tweak the output in the direction you want. Stargazer does have sensible defaults and useful settings, but one drawback is that it cannot be adjusted using `kableExtra` at the end. Have a look at the result in table \@ref(tab:m123-stargazer) and compare this to the corresponding source code to see how it works.

\enlargethispage*{1cm}

```{r}
#| echo = TRUE,
#| message = FALSE,
#| warning = FALSE,
#| results = "asis"
stargazer(m1, m2, m3,
          title = "Comparison of three linear models using stargazer",
          label = "tab:m123-stargazer",
          covariate.labels = c("Constant",
                               "Year = 2008",
                               "6 Cylinders",
                               "8 Cylinders",
                               "Displacement",
                               "2008 $\\times$ 6 Cylinders",
                               "2008 $\\times$ 8 Cylinders"),
          ci = TRUE, ci.level = 0.95, header = FALSE, digits = 2,
          intercept.bottom = FALSE, intercept.top = TRUE, 
          table.placement = "H", font.size = "small")
```


If you want to produce an inline result from a specific model you can do this as before by hand, or you can use the package `gtsummary`, which gives you the possibility of directly reporting statistical results using inline functions like `tbl_summary()` and `inline_text()`. As an example, the coefficient for six cylinders in model 3 is $`r inline_text(tbl_regression(m3), variable = "cyl", level = "6 Cylinders", pattern = "{estimate}~({conf.level}\\%~CI~{conf.low},~{conf.high};~{p.value})")`$. Have a look in the source code to see how this is accomplished, but be aware that the argument `pattern` within the function call to `inline_text()` must be provided in this case because we want to render a PDF-file and `gtsummary` is currently mainly aiming at HTML-output. The difference between the numbers in the inline output and table \@ref(tab:m123-stargazer) are due to rounding. If you want to look into the given capabilities of `gtsummary` regarding inline reporting, check out this [\textcolor{blue}{presentation}](https://www.danieldsjoberg.com/clinical-reporting-gtsummary-rmed/slides/#/introduction) and the [\textcolor{blue}{package documentation}](https://www.danieldsjoberg.com/gtsummary/).


### Generalized linear regression models

\Acp{glm}, first introduced in this comprehensive manner by @nelder1972 are models in which the outcome does not need to belong to a normal distribution, but where the simple linear model is just a special case. For example, the outcome can belong to a $Poisson$ or a $negative-binomial$ distribution (for count data, i.e., only integer values and no value less than zero), to a $Gamma$ distribution (for only positive decimal values, not only integers), to a $binomial$ distribution (for the number of success in a fixed set of trials), or to a $bernoulli$ distribution, which is a simple case of the $binomial$ distribution, where the outcome can only be either one or zero (i.e., yes/no, true/false). There are a lot of possible ways and also user provided packages which make it feasible to model such outcomes using the most appropriate distribution for the data at hand, but the starting point is mainly the function `glm()` from the stats package. 

This document can not introduce you to the statistical concepts behind \acp{glm} in general, but I want to give one example of logistic regression to demonstrate the general workflow and to give examples of plotting marginal means. For this purpose, I will use the famous titanic data set [@dawson1995], which was further greatly updated and improved by Thomas Cason using the Encyclopedia Titanica to create a new dataset called `titanic3`, which can be obtained [\textcolor{blue}{here}](https://hbiostat.org/data/) and which can also be obtained through the `Hmisc` package [@Hmisc2022].

\enlargethispage*{1cm}

```{r}
titanic <- read_csv("02-data/titanic3.csv",
    col_types = cols(
        pclass = col_double(),
        survived = col_double(),
        name = col_character(),
        sex = col_character(),
        age = col_double(),
        sibsp = col_double(),
        parch = col_double(),
        ticket = col_character(),
        fare = col_double(),
        cabin = col_character(),
        embarked = col_character(),
        boat = col_character(),
        body = col_double(),
        home.dest = col_character()
    ), lazy = FALSE)
titanic$pclass <- factor(titanic$pclass, 
                         levels = c(1,2,3), 
                         labels = c("1st", "2nd", "3rd"))
```

The original (non-enhanced) dataset based on data originally collected by the British Board of Trade also comes with the `datasets` package in `R`, but provides only the variables `class`, `sex`, `age`, and `survived` for each person on board of the Titanic. The enhanced version additionally includes variables like `age`, the ticket `fare`, the `cabin` or the place where the person `embarked` and some others. Next to that, the variable `age` is changed from a categorical one (child vs. adult) to the actual numeric age in years. The data set comprises $`r dim(titanic)[1]`$ observations. 

In the next step, we want to predict if someone survived the Titanic based on the variables `pclass`, `sex` and `age` and the interaction between `sex` and `age`. The dependent variable is `survived`, encoded as $0$ or $1$, which means the model predicts the mean probability of surviving the Titanic.

```{r}
mlog1 <- glm(survived ~ pclass + sex + age + sex:age, 
             data = titanic, family = binomial)
summary(mlog1)
```

Again, the default console output is not feasible for a written report, but is printed here to explain some points about the model. The estimated numbers here are on the scale of the linear predictor, that is, they cannot be interpreted as probability values, which is why you see negative numbers. In logistic regression, a linear combination of covariate values (which can take values between $\pm\infty$) is converted to the scale of a probability (between $0$ and $1$) using the logit link function, which is the inverse of the standard logistic function $\sigma(x) = 1 / ( 1 + e^{-x})$, with its definition stated in see equation \@ref(eq:logit).


\begin{equation} 
  logit(\theta_{i}) = ln(\frac{\theta_{i}}{1 - \theta_{i}}) = \beta_{0} + \beta_{1} \times x_{1} + ... + \beta_{p} \times x_{p}
  (\#eq:logit)
\end{equation} 

That means that after exponentiating both sides we have the odds, see equation \@ref(eq:odds), which are easier to interpret.

\begin{equation} 
  odds = \theta_{i} = \frac{\theta_{i}}{1 - \theta_{i}} = e^{\beta_{0} + \beta_{1} \times x_{1} + ... + \beta_{p} \times x_{p}}
  (\#eq:odds)
\end{equation} 

In a logistic regression, the response being modeled is the $log(odds)$ that $Y = 1$. Therefore, the regression coefficients give the change in log(odds) in the response for a unit change in the predictor variable, holding all other predictor variables constant. The odds ratio can then be defined as in equation \@ref(eq:exponential). 

\begin{equation}
  OR ={\frac {\operatorname {odds} (x+1)}{\operatorname {odds} (x)}}={\frac {e^{\beta _{0}+\beta _{1}(x+1)}}{e^{\beta _{0}+\beta _{1}x}}}=e^{\beta _{1}}
  (\#eq:exponential)
\end{equation}

This exponential relationship, see equation \@ref(eq:exponential), provides an interpretation for $\beta_{1}$: The odds multiply by $e^{\beta_{1}}$ for every 1-unit increase in x. So, if we take the coefficient for being male in the above model ($`r coefficients(mlog1)["sexmale"]`$) and take the exponential of it ($\approx~`r exp(coefficients(mlog1)["sexmale"])`$), we can say that a male passenger has a chance of surviving when compared to a female passenger which is reduced by a factor of `r exp(coefficients(mlog1)["sexmale"])`. That roughly means that a male passenger only has a $`r (1 -  round(exp(coefficients(mlog1)["sexmale"]), digits = 2)) * 100`$% lower chance of survival than a female passenger. The probability value for the female passenger is not directly obvious from the above model output, because it serves as a baseline category in this model and is not explicitly named in the above output but is indicated by the intercept.

Using package `jtools` (which utilizes package `huxtable` for table formatting), one can get another decent model summary table (see table \@ref(tab:jtools-mlog1)), but you can as well use the aforementioned packages like `modelsummary` or `stargazer`.

```{r}
#| label = "jtools-mlog1"
export_summs(mlog1, digits = 2, error_pos = "right", exp = TRUE,
             error_format = "[{conf.low}, {conf.high}]",
             model.names = "Dependent variable: Survived",
             coefs = c("Intercept" = "(Intercept)",
                       "2nd Passenger Class" = "pclass2nd",
                       "3rd Passenger Class" = "pclass3rd",
                       "Male Passenger" = "sexmale",
                       "Age" = "age",
                       "Male Passenger x Age" = "sexmale:age")) %>% 
  huxtable::set_caption('A logistic regression model for the titanic data set using package jtools')
```

Another way to produce such a model table is using package `gtsummary` in conjunction with `kableExtra`, see table \@ref(tab:gtsummary-mlog1). The only problem here is that you have to "rewrite" the column names because on the way from `gtsummary` output to `kableExtra`, the superscripts are lost which renders the footnote a little bit without meaning.

```{r}
#| label = "gtsummary-mlog1",
#| message = FALSE
tbl_regression(mlog1, exponentiate = TRUE,
               pvalue_fun = ~style_pvalue(.x, digits = 2),
               label = list(pclass ~ "Passenger Class",
                            sex ~ "Sex",
                            age ~ "Age"
                            )) %>% 
    add_global_p() %>%  # add global p-value 
    add_nevent() %>%    # add number of events of the outcome
    add_q() %>%         # adjusts global p-values for multiple testing
    bold_p() %>%        # bold p-values under a given threshold (default 0.05)
    bold_p(t = 0.05, q = TRUE) %>% # bold q-values under the threshold of 0.05
    bold_labels() %>% 
    italicize_levels() %>% 
    as_kable_extra(format = "latex", booktabs = TRUE, 
                   linesep = "", escape = FALSE,
      caption = 'A logistic regression model for the titanic data set using package gtsummary',
      col.names = c("Coefficient", "$\\mathrm{Event}~N$", "$OR^{1}$", 
                    "$95~\\mathrm{CI}^{1}$",
                    "$p-\\mathrm{value}$",
                    "$q-\\mathrm{value}^{2}$")) %>% 
    kable_styling(latex_options = c("striped", "HOLD_position")) 
```

As you have seen, there are a lot of possibilities to generate model and summary tables. It depends on what you need to do, what amount of time you are willing to invest into getting what you want and how satisfied you are with the output generated by one of these helper packages. There are lots of possibilities to tweak the output in more than one way and I would guess that in 90% of the cases, a pre-generated model table is doing the job just great. But, in case it does not, you can always resort to writing down a custom \LaTeX\ table on your own and fill in the cells with inline R chunks that give you exactly the number you want. In this way you can completely decide how your table should look like. 


### Automated report generation

Another automated way to report a model is using the `report` package [@Makowski2021], for example:

```{r}
#| results = "asis",
#| comment = ""
report(mlog1)
```

All the text since the last code chunk was automatically generated by this one function call. have a look at the chunk options to see how this is printed as normal text and not as console output.


## Plotting statistical models

To really understand what a regression model is telling you, you should not just stare at a summary table but you should plot the predictions of a model. There, you can see how the dependent variable is changing when a predictor variable is changing, normally while holding all other predictors constant (e.g., at $0$ or the sample mean). That means that you need to calculate the predicted values from the model given different input values for the predictors, calculate the lower and upper confidence intervals according to some level of confidence (normally 95%) and plot all these together. In the case of a \ac{glm} one should decide if these numbers should be transformed from the scale of the linear predictor to the scale of the response, for example in case of a logistic regression model, if you should plot the probability instead of the log odds.

There are several packages available that make this task easier. Some of them are `effects` [@fox2003, @fox2019], `ggeffects` [@Luedecke2018], `jtools` [@jtools], `see` [@Luedecke-see2021] or `emmeans` [for estimated marginal means, @Lenth2022]. 

A first example using `ggeffects`:

```{r}
#| label = "pclass-ggeffects",
#| fig.cap = "Predicted probabilities of survival for each passenger class",
#| fig.height = 3,
#| fig.width = 4.5,
#| fig.align = "center",
#| message = FALSE,
#| fig.pos = "H"
eff1 <- ggpredict(mlog1, terms = "pclass")
plot(eff1) + labs(x = "Passenger Class", y = "Probability of Survival",
                  title = element_blank()) +
    scale_y_continuous(labels = scales::percent, limits = c(0,0.65))
```

Here, you can see another example to visualize the interaction between `sex` and `age`, that is, an interaction between a continuous and a categorical predictor.

```{r}
#| label = "sex-age-ggeffects",
#| fig.width = 5,
#| fig.height = 3.5,
#| fig.cap = "Predicted probabilities of survival dependend on sex and age",
#| fig.align = "center",
#| fig.pos = "H"
eff2 <- ggpredict(mlog1, terms = c("age [all]", "sex"))
plot(eff2) + labs(x = "Age", y = "Probability of Survival",
                  title = element_blank()) + 
    theme(legend.position = "bottom") +
    guides(color = guide_legend(title = "Sex"))
```

Coming back to the multiple regression model from above (see section \@ref(reg-models)), especially model 1 (see table \@ref(tab:m123-modelsummary)), we can generate one visualization for all the main effects and one for the interaction. In a "real" scientific work you would not present the main effects for themselves in presence of an interaction involving these main effects, but for demonstration purposes, we want to generate four visualizations and put them together in one plot using the package `patchwork` [@Pedersen2022]. The code for this is placed on the following page, and the figure it produces comes on the next one. By the way, have a look into the chunk options for the last chunk, where both the arguments `fig.cap` and `fig.scap` are used to produce a caption and a short caption for figure \@ref(fig:patchwork-plot), where the former is printed under the figure itself and the latter is used in the list of figures to have a smaller output in the frontmatter. 

\newpage

```{r}
#| label = "patchwork-plot",
#| warning = FALSE,
#| message = FALSE,
#| fig.height = 7,
#| fig.width = 7,
#| fig.align = "center",
#| fig.cap = "One overall plot with four subplots: (A) predictor Year, (B) predictor Cylinders, (C) predictor Displacement, and (D) the interaction between Year x Cylinders",
#| fig.scap = "One overall plot with four subplots",
#| fig.pos = "H"
m1_year <- ggpredict(m1, terms = "year")
m1_cyl <- ggpredict(m1, terms = "cyl")
m1_displ <- ggpredict(m1, terms = "displ [all]")
m1_year_cyl <- ggpredict(m1, terms = c("cyl", "year"))

m1_year_plot <- plot(m1_year) + labs(x = "Year", 
    y = "Highway Miles per Gallon", title = element_blank()) + 
    scale_y_continuous(limits = c(0, NA), 
                       breaks = seq(from = 0, to = 50, by = 5))
m1_cyl_plot <- plot(m1_cyl) + labs(x = "", 
    y = "Highway Miles per Gallon", title = element_blank()) + 
    scale_y_continuous(limits = c(0, NA), 
                       breaks = seq(from = 0, to = 50, by = 5))
m1_displ_plot <- plot(m1_displ) + labs(x = "Displacement", 
    y = "Highway Miles per Gallon", title = element_blank()) + 
    scale_y_continuous(limits = c(0, NA), 
                       breaks = seq(from = 0, to = 50, by = 5))
m1_year_cyl_plot <- plot(m1_year_cyl) + labs(x = "", 
    y = "Highway Miles per Gallon", title = element_blank()) + 
    guides(color = guide_legend(title = "Year")) + 
    scale_y_continuous(limits = c(0, NA), 
                       breaks = seq(from = 0, to = 50, by = 5))

m1_year_plot + m1_cyl_plot + m1_displ_plot + m1_year_cyl_plot +
    plot_annotation(tag_levels = 'A') +
    plot_layout(guides = 'collect') &
    theme(legend.position = 'bottom')
```


> This is the end! Good luck with writing your own report or thesis using this template!

